{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if an image has alpha channel (RGBA) or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "items = [\n",
    "    cv2.imread('./Images/Lips/Lips 1.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/Beards/Beard 1.png', cv2.IMREAD_UNCHANGED),\n",
    "]\n",
    "\n",
    "for item in items:\n",
    "    num_chan = item.shape[2]\n",
    "\n",
    "    if num_chan == 4:\n",
    "        print(f\"La imagen tiene un canal alfa (RGBA)\")\n",
    "    else:\n",
    "        print(f\"La imagen tiene un canal NO alfa (NO RGBA)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------- Multiple face detection -----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "hats = [\n",
    "    cv2.imread('./Images/No_trim/Hat 1.png', cv2.IMREAD_UNCHANGED), \n",
    "    cv2.imread('./Images/No_trim/Hat 2.png', cv2.IMREAD_UNCHANGED), \n",
    "    cv2.imread('./Images/No_trim/Hat 3.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/Hat 4.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/Hat 5.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/Hat 6.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/Hat 7.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/Hat 8.png', cv2.IMREAD_UNCHANGED)\n",
    "]\n",
    "\n",
    "current_hat = 0\n",
    " \n",
    "# initialize dlib's face detector (HOG-based) and then create\n",
    "# the facial landmark predictor\n",
    "p = \"./shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(p)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    " \n",
    "while True:\n",
    "    # load the input image and convert it to grayscale\n",
    "    _, image = cap.read()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_rgba = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
    "        \n",
    "    # detect faces in the grayscale image\n",
    "    rects = detector(gray, 0)\n",
    "    \n",
    "    # loop over the face detections\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "        top_head_x = int(np.mean(shape[0:27, 0]))\n",
    "        top_head_y = int(np.mean(shape[0:27, 1]))\n",
    "\n",
    "        hat_width = int(1.5 * rect.width())\n",
    "        hat_height = hat_width * hats[current_hat].shape[0] // hats[current_hat].shape[1]\n",
    "\n",
    "        x = top_head_x - hat_width // 2\n",
    "        y = top_head_y - hat_height\n",
    "\n",
    "        hat_resized = cv2.resize(hats[current_hat], (hat_width, hat_height))\n",
    "\n",
    "        for i in range(hat_height):\n",
    "            for j in range(hat_width):\n",
    "                if 0 <= y + i < image.shape[0] and 0 <= x + j < image.shape[1] and hat_resized[i, j, 3] != 0:\n",
    "                    image_rgba[y + i, x + j] = hat_resized[i, j]\n",
    "    \n",
    "    # show the output image with the face detections + facial landmarks\n",
    "    cv2.imshow(\"Hats Filter\", image_rgba)\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif k >= ord('1') and k <= ord('8'):\n",
    "        current_hat = k - ord('1')\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beards & moustaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "beards = [\n",
    "    cv2.imread('./Images/No_trim/Beard 1.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/Beard 2.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/Beard 3.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/Beard 4.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/Beard 5.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/Beard 6.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/Beard 7.png', cv2.IMREAD_UNCHANGED)\n",
    "]\n",
    "\n",
    "current_beard = 0\n",
    " \n",
    "# initialize dlib's face detector (HOG-based) and then create\n",
    "# the facial landmark predictor\n",
    "p = \"./shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(p)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    " \n",
    "while True:\n",
    "    # load the input image and convert it to grayscale\n",
    "    _, image = cap.read()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_rgba = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
    "        \n",
    "    # detect faces in the grayscale image\n",
    "    rects = detector(gray, 0)\n",
    "    \n",
    "    # loop over the face detections\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "        top_head_x = int(np.mean(shape[0:27, 0]))\n",
    "        top_head_y = int(np.mean(shape[0:27, 1]))\n",
    "\n",
    "        beard_width = int(1.5 * rect.width())\n",
    "        beard_height = beard_width * beards[current_beard].shape[0] // beards[current_beard].shape[1]\n",
    "\n",
    "        x = top_head_x - beard_width // 2\n",
    "        y = int(0.98 * shape[30][1])\n",
    "\n",
    "        beard_resized = cv2.resize(beards[current_beard], (beard_width, beard_height))\n",
    "\n",
    "        for i in range(beard_height):\n",
    "            for j in range(beard_width):\n",
    "                if 0 <= y + i < image.shape[0] and 0 <= x + j < image.shape[1] and beard_resized[i, j, 3] != 0:\n",
    "                    image_rgba[y + i, x + j] = beard_resized[i, j]\n",
    "    \n",
    "    # show the output image with the face detections + facial landmarks\n",
    "    cv2.imshow(\"Beards and Moustaches Filter\", image_rgba)\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif k >= ord('1') and k <= ord('7'):\n",
    "        current_beard = k - ord('1')\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lips code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "\n",
    "lips_items = [\n",
    "    cv2.imread('./Images/No_trim/Lips 1.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/Lips 2.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/Lips 3.png', cv2.IMREAD_UNCHANGED),\n",
    "    #cv2.imread('./Images/No_trim/sexy2.png', cv2.IMREAD_UNCHANGED),\n",
    "    #cv2.imread('./Images/No_trim/vampire1.png', cv2.IMREAD_UNCHANGED),\n",
    "]\n",
    "\n",
    "current_item = 0\n",
    "\n",
    "# Initialize dlib's face detector (HOG-based) and create the facial landmark predictor\n",
    "p = \"./shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(p)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "while True:\n",
    "    # Load the input image and convert it to grayscale\n",
    "    _, image = cap.read()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the grayscale image\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "        # Get the coordinates of the lips\n",
    "        lips = shape[48:68]\n",
    "\n",
    "        # Calculate the center of the lips\n",
    "        lips_center = (int((lips[0][0] + lips[6][0]) / 2), int((lips[0][1] + lips[6][1]) / 2))\n",
    "\n",
    "        # Calculate the width and height for the overlay image\n",
    "        overlay_width = int((lips[6][0] - lips[0][0]))\n",
    "        overlay_height = int(0.8 * overlay_width)\n",
    "\n",
    "        # Resize the overlay image to fit the lips\n",
    "        overlay_image_resized = cv2.resize(lips_items[current_item], (overlay_width, overlay_height)) #cv2.resize(beard, (overlay_width, overlay_height))\n",
    "\n",
    "        # Calculate the position to overlay the image on the lips\n",
    "        x_pos = lips_center[0] - overlay_width // 2\n",
    "        y_pos = lips_center[1] - overlay_height // 2\n",
    "\n",
    "        # Ensure that the overlay image is within the bounds of the original image\n",
    "        if x_pos >= 0 and y_pos >= 0 and x_pos + overlay_width <= image.shape[1] and y_pos + overlay_height <= image.shape[0]:\n",
    "            # Create a mask based on the alpha channel of the overlay image\n",
    "            mask = overlay_image_resized[:, :, 3] / 255.0\n",
    "            mask = cv2.merge([mask, mask, mask])\n",
    "\n",
    "            # Mix the two images using the mask\n",
    "            overlay_region = overlay_image_resized[:, :, 0:3]\n",
    "            image[y_pos:y_pos + overlay_height, x_pos:x_pos + overlay_width] = (1 - mask) * image[y_pos:y_pos + overlay_height, x_pos:x_pos + overlay_width] + mask * overlay_region\n",
    "\n",
    "    # Show the output image with the face detections + facial landmarks\n",
    "    cv2.imshow(\"Lips Filter\", image)\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif k >= ord('1') and k <= ord('3'):\n",
    "        current_item = k - ord('1')\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "\n",
    "# Initialize dlib's face detector (HOG-based) and create the facial landmark predictor\n",
    "p = \"./shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(p)\n",
    "\n",
    "glasses_items = [\n",
    "    cv2.imread(\"./Images/No_trim/Glasses 1.png\", cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/Glasses 2.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/Glasses 3.png', cv2.IMREAD_UNCHANGED),\n",
    "]\n",
    "\n",
    "current_item = 0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Load the input image and convert it to grayscale\n",
    "    _, image = cap.read()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the grayscale image\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "    # loop over the face detections\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the facial landmark (x, y)-coordinates to a NumPy array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "        # Detect eyes\n",
    "        left_eye = shape[42:48]\n",
    "        right_eye = shape[36:42]\n",
    "\n",
    "        # Calculate the center of both eyes\n",
    "        left_eye_center = np.mean(left_eye, axis=0).astype(int)\n",
    "        right_eye_center = np.mean(right_eye, axis=0).astype(int)\n",
    "\n",
    "        # Calculate the center between the eyes\n",
    "        eyes_center = ((left_eye_center[0] + right_eye_center[0]) // 2, (left_eye_center[1] + right_eye_center[1]) // 2)\n",
    "\n",
    "        # Calculate the scale factor for the glasses\n",
    "        distance = abs(left_eye_center[0] - right_eye_center[0])\n",
    "        scale_factor = 2.0 * distance / glasses_items[current_item].shape[1]  # Adjust scale as needed\n",
    "\n",
    "        # Resize the glasses image\n",
    "        new_glasses = cv2.resize(glasses_items[current_item], (0, 0), fx=scale_factor, fy=scale_factor)\n",
    "\n",
    "        # Calculate the position to place the glasses centered between the eyes\n",
    "        x_offset = eyes_center[0] - new_glasses.shape[1] // 2\n",
    "        y_offset = eyes_center[1] - new_glasses.shape[0] // 2\n",
    "\n",
    "        # Superpose the glasses on the face\n",
    "        for c in range(0, 3):\n",
    "            image[y_offset:y_offset + new_glasses.shape[0], x_offset:x_offset + new_glasses.shape[1], c] = (\n",
    "                image[y_offset:y_offset + new_glasses.shape[0], x_offset:x_offset + new_glasses.shape[1], c] * (1 - new_glasses[:, :, 3] / 255.0) +\n",
    "                new_glasses[:, :, c] * (new_glasses[:, :, 3] / 255.0)\n",
    "            )\n",
    "\n",
    "    # show the output image with the face detections + facial landmarks\n",
    "    cv2.imshow(\"Glasses Filter\", image)\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif k >= ord('1') and k <= ord('3'):\n",
    "        current_item = k - ord('1')\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------- Landmark code face detectection -----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import FaceNormalizationUtils as faceutils\n",
    "import FaceDetectors\n",
    "import os\n",
    "\n",
    "normalizatorHS = faceutils.Normalization()\n",
    "FDet = FaceDetectors.FaceDetector()\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "hats_file = './Images/Hats/'\n",
    "hats = os.listdir(hats_file)\n",
    "hats_index = 0\n",
    "\n",
    "frames_no_face = 0\n",
    "umbral_frames_no_face  = 5\n",
    "next_index = True\n",
    "\n",
    "# Webcam connection\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Check for other cameras\n",
    "if not cap.isOpened():\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    if not cap.isOpened():\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            print('Camera error')\n",
    "            exit(0)\n",
    "        else:\n",
    "            print('Camera 0')\n",
    "    else:\n",
    "        print('Camera 1')\n",
    "else:\n",
    "    print('Camera 0')\n",
    "\n",
    "imodoF = 2\n",
    "imodoE = 1\n",
    "\n",
    "debug = 0\n",
    "\n",
    "#Set camera resolution\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    " \n",
    "while True:\n",
    "    # Get frame\n",
    "    t = time.time()\n",
    "    ret, image = cap.read()\n",
    "    # For HS normalization\n",
    "    B, G, R = cv2.split(image)\n",
    "    # Load the input image and convert it to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_rgba = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
    "    # Detect faces in the grayscale image\n",
    "    values = FDet.SingleFaceEyesDetection(image, FDet.FaceDetectors[imodoF], FDet.EyeDetectors[imodoE])\n",
    "    if values is not None:\n",
    "        face, eyes, shape = values\n",
    "\n",
    "        if len(shape) == 0:\n",
    "            frames_no_face  += 1\n",
    "        else:\n",
    "            frames_no_face  = 0\n",
    "            next_index = True\n",
    "\n",
    "        if frames_no_face  >= umbral_frames_no_face  and next_index:\n",
    "            hats_index = (hats_index + 1) % len(hats)\n",
    "            frames_no_face  = 0\n",
    "            next_index = False\n",
    "        \n",
    "        if len(shape) > 0:\n",
    "            top_head_x = shape[0][0]\n",
    "            top_head_y = shape[19][1]\n",
    "\n",
    "            hat = cv2.imread(os.path.join(hats_file, hats[hats_index]), cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "            hat_width = shape[16][0] - shape[0][0]\n",
    "            hat_height = hat_width * hat.shape[0] // hat.shape[1] \n",
    "                      \n",
    "            hat_resized = cv2.resize(hat, (hat_width, hat_height))\n",
    "\n",
    "            x = top_head_x \n",
    "            y = top_head_y - hat_height - 45\n",
    "\n",
    "            for i in range(hat_height):\n",
    "                for j in range(hat_width):\n",
    "                    if 0 <= y + i < image.shape[0] and 0 <= x + j < image.shape[1] and hat_resized[i, j, 3] != 0:\n",
    "                        image_rgba[y + i, x + j] = hat_resized[i, j]\n",
    "\n",
    "    if debug:\n",
    "        print(\"Processing time : {:.3f}\".format(time.time() - t))\n",
    "\n",
    "    # Show resulting image\n",
    "    cv2.putText(image_rgba, FDet.FaceDetectors[imodoF], (10, 20), font, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    if imodoF == 1 or imodoF == 2:\n",
    "        cv2.putText(image_rgba, FDet.EyeDetectors[imodoE], (50, 20), font, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('Cam', image_rgba)\n",
    "\n",
    "    tec = cv2.waitKey(40)\n",
    "    if tec & tec == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import FaceNormalizationUtils as faceutils\n",
    "import FaceDetectors\n",
    "import os\n",
    "\n",
    "normalizatorHS = faceutils.Normalization()\n",
    "\n",
    "FDet = FaceDetectors.FaceDetector()\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "beards_file = './Images/Beards/'\n",
    "beards = os.listdir(beards_file)\n",
    "beards_index = 0\n",
    "\n",
    "frames_no_face = 0\n",
    "umbral_frames_no_face  = 5\n",
    "next_index = True\n",
    "\n",
    "# Webcam connection\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Check for other cameras\n",
    "if not cap.isOpened():\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    if not cap.isOpened():\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            print('Camera error')\n",
    "            exit(0)\n",
    "        else:\n",
    "            print('Camera 0')\n",
    "    else:\n",
    "        print('Camera 1')\n",
    "else:\n",
    "    print('Camera 0')\n",
    "\n",
    "imodoF = 2\n",
    "imodoE = 1\n",
    "\n",
    "debug = 0\n",
    "\n",
    "#Set camera resolution\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    " \n",
    "while True:\n",
    "    # Get frame\n",
    "    t = time.time()\n",
    "    ret, image = cap.read()\n",
    "    # For HS normalization\n",
    "    B, G, R = cv2.split(image)\n",
    "    # Load the input image and convert it to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_rgba = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
    "    # Detect faces in the grayscale image\n",
    "    values = FDet.SingleFaceEyesDetection(image, FDet.FaceDetectors[imodoF], FDet.EyeDetectors[imodoE])\n",
    "    if values is not None:\n",
    "        face, eyes, shape = values\n",
    "\n",
    "        if len(shape) == 0:\n",
    "            frames_no_face  += 1\n",
    "        else:\n",
    "            frames_no_face  = 0\n",
    "            next_index = True\n",
    "\n",
    "        if frames_no_face  >= umbral_frames_no_face  and next_index:\n",
    "            beards_index = (beards_index + 1) % len(beards)\n",
    "            frames_no_face  = 0\n",
    "            next_index = False\n",
    "        \n",
    "        if len(shape) > 0:\n",
    "            top_head_x = shape[2][0] - 3\n",
    "            top_head_y = shape[30][1]\n",
    "\n",
    "        # cv2.circle(image_rgba, (shape[33][0], shape[33][1]), 2, (0, 255, 0), -1)\n",
    "\n",
    "        # cv2.circle(image_rgba, (shape[2][0], shape[2][1]), 2, (0, 255, 0), -1)\n",
    "        # cv2.circle(image_rgba, (shape[14][0], shape[14][1]), 2, (0, 0, 255), -1)\n",
    "\n",
    "            beard = cv2.imread(os.path.join(beards_file, beards[beards_index]), cv2.IMREAD_UNCHANGED)\n",
    "        \n",
    "            beard_width = (shape[15][0]) - (shape[1][0])\n",
    "            beard_height = shape[8][1] - shape[33][1] + 50\n",
    "\n",
    "            beard_resized = cv2.resize(beard, (beard_width, beard_height))\n",
    "\n",
    "            x = top_head_x \n",
    "            y = top_head_y\n",
    "\n",
    "        for i in range(beard_height):\n",
    "            for j in range(beard_width):\n",
    "                if 0 <= y + i < image.shape[0] and 0 <= x + j < image.shape[1] and beard_resized[i, j, 3] != 0:\n",
    "                    image_rgba[y + i, x + j] = beard_resized[i, j]\n",
    "        \n",
    "    if debug:\n",
    "        print(\"Processing time : {:.3f}\".format(time.time() - t))\n",
    "\n",
    "    # Show resulting image\n",
    "    cv2.putText(image_rgba, FDet.FaceDetectors[imodoF], (10, 20), font, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    if imodoF == 1 or imodoF == 2:\n",
    "        cv2.putText(image_rgba, FDet.EyeDetectors[imodoE], (50, 20), font, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('Cam', image_rgba)\n",
    "\n",
    "    tec = cv2.waitKey(40)\n",
    "    if tec & tec == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moustaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import FaceNormalizationUtils as faceutils\n",
    "import FaceDetectors\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "normalizatorHS = faceutils.Normalization()\n",
    "\n",
    "FDet = FaceDetectors.FaceDetector()\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "moustaches_file = './Images/Moustaches/'\n",
    "moustaches = os.listdir(moustaches_file)\n",
    "moustaches_index = 0\n",
    "\n",
    "frames_no_face = 0\n",
    "umbral_frames_no_face  = 5\n",
    "next_index = True\n",
    "\n",
    "# Webcam connection\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Check for other cameras\n",
    "if not cap.isOpened():\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    if not cap.isOpened():\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            print('Camera error')\n",
    "            exit(0)\n",
    "        else:\n",
    "            print('Camera 0')\n",
    "    else:\n",
    "        print('Camera 1')\n",
    "else:\n",
    "    print('Camera 0')\n",
    "\n",
    "imodoF = 2\n",
    "imodoE = 1\n",
    "\n",
    "debug = 0\n",
    "\n",
    "#Set camera resolution\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    " \n",
    "while True:\n",
    "    # Get frame\n",
    "    t = time.time()\n",
    "    ret, image = cap.read()\n",
    "    # For HS normalization\n",
    "    B, G, R = cv2.split(image)\n",
    "    # Load the input image and convert it to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_rgba = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "    # Detect faces in the grayscale image\n",
    "    values = FDet.SingleFaceEyesDetection(image, FDet.FaceDetectors[imodoF], FDet.EyeDetectors[imodoE])\n",
    "    if values is not None:\n",
    "        face, eyes, shape = values\n",
    "\n",
    "        if len(shape) == 0:\n",
    "            frames_no_face  += 1\n",
    "        else:\n",
    "            frames_no_face  = 0\n",
    "            next_index = True\n",
    "\n",
    "        if frames_no_face  >= umbral_frames_no_face  and next_index:\n",
    "            moustaches_index = (moustaches_index + 1) % len(moustaches)\n",
    "            frames_no_face  = 0\n",
    "            next_index = False\n",
    "        \n",
    "        if len(shape) > 0:\n",
    "            top_head_x = shape[48][0]\n",
    "            top_head_y = shape[33][1]\n",
    "\n",
    "            beard = cv2.imread(os.path.join(moustaches_file, moustaches[moustaches_index]), cv2.IMREAD_UNCHANGED)\n",
    "        \n",
    "            nose_x, nose_y = shape[33]\n",
    "            upper_lip_x = int((shape[48][0] + shape[54][0]) / 2)\n",
    "            upper_lip_y = np.mean(shape[48:54, 1])\n",
    "\n",
    "            y_offset = int((nose_y - upper_lip_y) * 0.8)\n",
    "            beard_width = int(shape[54][0] - shape[48][0]) + 50\n",
    "            beard_height = int(shape[51][1] - shape[33][1]) + 5\n",
    "\n",
    "            beard_resized = cv2.resize(beard, (beard_width, beard_height))\n",
    "\n",
    "            x = int(upper_lip_x - beard_width / 2)\n",
    "            y = int(upper_lip_y + y_offset)\n",
    "\n",
    "            for i in range(beard_height):\n",
    "                for j in range(beard_width):\n",
    "                    if 0 <= y + i < image.shape[0] and 0 <= x + j < image.shape[1] and beard_resized[i, j, 3] != 0:\n",
    "                        image_rgba[y + i, x + j] = beard_resized[i, j]\n",
    "        \n",
    "    if debug:\n",
    "        print(\"Processing time : {:.3f}\".format(time.time() - t))\n",
    "\n",
    "    # Show resulting image\n",
    "    cv2.putText(image_rgba, FDet.FaceDetectors[imodoF], (10, 20), font, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    if imodoF == 1 or imodoF == 2:\n",
    "        cv2.putText(image_rgba, FDet.EyeDetectors[imodoE], (50, 20), font, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('Cam', image_rgba)\n",
    "\n",
    "    tec = cv2.waitKey(40)\n",
    "    if tec & tec == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import FaceNormalizationUtils as faceutils\n",
    "import FaceDetectors\n",
    "import os\n",
    "\n",
    "normalizatorHS = faceutils.Normalization()\n",
    "FDet = FaceDetectors.FaceDetector()\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "lips_file = './Images/Lips/'\n",
    "lips = os.listdir(lips_file)\n",
    "lips_index = 0\n",
    "\n",
    "frames_no_face = 0\n",
    "umbral_frames_no_face  = 5\n",
    "next_index = True\n",
    "\n",
    "# Webcam connection\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Check for other cameras\n",
    "if not cap.isOpened():\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    if not cap.isOpened():\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            print('Camera error')\n",
    "            exit(0)\n",
    "        else:\n",
    "            print('Camera 0')\n",
    "    else:\n",
    "        print('Camera 1')\n",
    "else:\n",
    "    print('Camera 0')\n",
    "\n",
    "imodoF = 2\n",
    "imodoE = 1\n",
    "\n",
    "debug = 0\n",
    "\n",
    "#Set camera resolution\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    "\n",
    "while True:\n",
    "    # Get frame\n",
    "    t = time.time()\n",
    "    ret, image = cap.read()\n",
    "    # For HS normalization\n",
    "    B, G, R = cv2.split(image)\n",
    "    # Load the input image and convert it to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_rgba = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "    # Detect faces in the grayscale image\n",
    "    values = FDet.SingleFaceEyesDetection(image, FDet.FaceDetectors[imodoF], FDet.EyeDetectors[imodoE])\n",
    "    if values is not None:\n",
    "        face, eyes, shape = values\n",
    "\n",
    "        if len(shape) == 0:\n",
    "            frames_no_face  += 1\n",
    "        else:\n",
    "            frames_no_face  = 0\n",
    "            next_index = True\n",
    "\n",
    "        if frames_no_face  >= umbral_frames_no_face  and next_index:\n",
    "            lips_index = (lips_index + 1) % len(lips)\n",
    "            frames_no_face  = 0\n",
    "            next_index = False\n",
    "\n",
    "        if len(shape) > 0:\n",
    "            top_head_x = shape[48][0]\n",
    "            top_head_y = shape[50][1]\n",
    "\n",
    "            lip = cv2.imread(os.path.join(lips_file, lips[lips_index]), cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "            lip_width = shape[54][0] - shape[48][0]\n",
    "            lip_height = shape[58][1] - shape[50][1]\n",
    "\n",
    "            lip_resized = cv2.resize(lip, (lip_width, lip_height))\n",
    "\n",
    "        # print(\"shape[50][0] - shape[58][0]\")\n",
    "        # print(\"boca_width\")\n",
    "        # print(boca_width)\n",
    "        # print(\"boca_height\")\n",
    "        # print(boca_height)\n",
    "\n",
    "        # cv2.circle(image_rgba, (shape[54][0], shape[54][1]), 2, (255, 0, 0), -1)\n",
    "        # cv2.circle(image_rgba, (shape[48][0], shape[48][1]), 2, (255, 0, 0), -1)\n",
    "        # cv2.circle(image_rgba, (shape[57][0], shape[57][1]), 2, (0, 255, 0), -1)\n",
    "        # cv2.circle(image_rgba, (shape[50][0], shape[50][1]), 2, (0, 255, 0), -1)\n",
    "\n",
    "        # boca_resized = cv2.resize(boca, (boca_width, boca_height))\n",
    "\n",
    "            x = top_head_x \n",
    "            y = top_head_y\n",
    "        \n",
    "            for i in range(lip_height):\n",
    "                for j in range(lip_width):\n",
    "                    if 0 <= y + i < image.shape[0] and 0 <= x + j < image.shape[1] and lip_resized[i, j, 3] != 0:\n",
    "                        image_rgba[y + i, x + j] = lip_resized[i, j]\n",
    "    \n",
    "    if debug:\n",
    "        print(\"Processing time : {:.3f}\".format(time.time() - t))\n",
    "        \n",
    "    # Show resulting image\n",
    "    cv2.putText(image_rgba, FDet.FaceDetectors[imodoF], (10, 20), font, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    if imodoF == 1 or imodoF == 2:\n",
    "        cv2.putText(image_rgba, FDet.EyeDetectors[imodoE], (50, 20), font, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('Cam', image_rgba)\n",
    "\n",
    "    tec = cv2.waitKey(40)\n",
    "    if tec & tec == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import FaceNormalizationUtils as faceutils\n",
    "import FaceDetectors\n",
    "import os\n",
    "\n",
    "normalizatorHS = faceutils.Normalization()\n",
    "\n",
    "FDet = FaceDetectors.FaceDetector()\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "glasses_file = './Images/Glasses/'\n",
    "glasses = os.listdir(glasses_file)\n",
    "glasses_index = 0\n",
    "\n",
    "frames_no_face = 0\n",
    "umbral_frames_no_face  = 5\n",
    "next_index = True\n",
    "\n",
    "# Webcam connection\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Check for other cameras\n",
    "if not cap.isOpened():\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    if not cap.isOpened():\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            print('Camera error')\n",
    "            exit(0)\n",
    "        else:\n",
    "            print('Camera 0')\n",
    "    else:\n",
    "        print('Camera 1')\n",
    "else:\n",
    "    print('Camera 0')\n",
    "\n",
    "imodoF = 2\n",
    "imodoE = 1\n",
    "\n",
    "debug = 0\n",
    "\n",
    "#Set camera resolution\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    "\n",
    "while True:\n",
    "    # Get frame\n",
    "    t = time.time()\n",
    "    ret, image = cap.read()\n",
    "    # For HS normalization\n",
    "    B, G, R = cv2.split(image)\n",
    "    # Load the input image and convert it to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_rgba = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
    "    # Detect faces in the grayscale image\n",
    "    values = FDet.SingleFaceEyesDetection(image, FDet.FaceDetectors[imodoF], FDet.EyeDetectors[imodoE])\n",
    "    if values is not None:\n",
    "        face, eyes, shape = values\n",
    "\n",
    "        if len(shape) == 0:\n",
    "            frames_no_face  += 1\n",
    "        else:\n",
    "            frames_no_face  = 0\n",
    "            next_index = True\n",
    "\n",
    "        if frames_no_face  >= umbral_frames_no_face  and next_index:\n",
    "            glasses_index = (glasses_index + 1) % len(glasses)\n",
    "            frames_no_face  = 0\n",
    "            next_index = False\n",
    "        \n",
    "        if len(shape) > 0:\n",
    "            top_head_x = shape[0][0]\n",
    "            top_head_y = shape[37][1]\n",
    "\n",
    "            glass = cv2.imread(os.path.join(glasses_file, glasses[glasses_index]), cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "            glass_width = shape[16][0] - shape[0][0]\n",
    "            glass_height = glass_width * glass.shape[0] // glass.shape[1] \n",
    "                        \n",
    "            glass_resized = cv2.resize(glass, (glass_width, glass_height))\n",
    "\n",
    "            x = top_head_x \n",
    "            y = top_head_y - (glass_height // 2) \n",
    "            \n",
    "            for i in range(glass_height):\n",
    "                for j in range(glass_width):\n",
    "                    if 0 <= y + i < image.shape[0] and 0 <= x + j < image.shape[1] and glass_resized[i, j, 3] != 0:\n",
    "                        image_rgba[y + i, x + j] = glass_resized[i, j]\n",
    "\n",
    "    if debug:\n",
    "        print(\"Processing time : {:.3f}\".format(time.time() - t))\n",
    "\n",
    "    # Show resulting image\n",
    "    cv2.putText(image_rgba, FDet.FaceDetectors[imodoF], (10, 20), font, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    if imodoF == 1 or imodoF == 2:\n",
    "        cv2.putText(image_rgba, FDet.EyeDetectors[imodoE], (50, 20), font, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('Cam', image_rgba)\n",
    "\n",
    "    tec = cv2.waitKey(40)\n",
    "    if tec & tec == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pig nose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "from math import hypot\n",
    "\n",
    "# Loading Camera and Nose image and Creating mask\n",
    "cap = cv2.VideoCapture(0)\n",
    "nose_image = cv2.imread(\"./Images/pig_nose.png\")\n",
    "_, frame = cap.read()\n",
    "rows, cols, _ = frame.shape\n",
    "nose_mask = np.zeros((rows, cols), np.uint8)\n",
    "\n",
    "# Loading Face detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"./shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    nose_mask.fill(0)\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(frame)\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray_frame, face)\n",
    "\n",
    "        # Nose coordinates\n",
    "        top_nose = (landmarks.part(29).x, landmarks.part(29).y)\n",
    "        center_nose = (landmarks.part(30).x, landmarks.part(30).y)\n",
    "        left_nose = (landmarks.part(31).x, landmarks.part(31).y)\n",
    "        right_nose = (landmarks.part(35).x, landmarks.part(35).y)\n",
    "\n",
    "        nose_width = int(hypot(left_nose[0] - right_nose[0],\n",
    "                           left_nose[1] - right_nose[1]) * 1.7)\n",
    "        nose_height = int(nose_width * 0.77)\n",
    "\n",
    "        # New nose position\n",
    "        top_left = (int(center_nose[0] - nose_width / 2),\n",
    "                              int(center_nose[1] - nose_height / 2))\n",
    "        bottom_right = (int(center_nose[0] + nose_width / 2),\n",
    "                       int(center_nose[1] + nose_height / 2))\n",
    "\n",
    "\n",
    "        # Adding the new nose\n",
    "        nose_pig = cv2.resize(nose_image, (nose_width, nose_height))\n",
    "        nose_pig_gray = cv2.cvtColor(nose_pig, cv2.COLOR_BGR2GRAY)\n",
    "        _, nose_mask = cv2.threshold(nose_pig_gray, 25, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        nose_area = frame[top_left[1]: top_left[1] + nose_height,\n",
    "                    top_left[0]: top_left[0] + nose_width]\n",
    "        nose_area_no_nose = cv2.bitwise_and(nose_area, nose_area, mask=nose_mask)\n",
    "        final_nose = cv2.add(nose_area_no_nose, nose_pig)\n",
    "\n",
    "        frame[top_left[1]: top_left[1] + nose_height,\n",
    "                    top_left[0]: top_left[0] + nose_width] = final_nose\n",
    "\n",
    "        #cv2.imshow(\"Nose area\", nose_area)\n",
    "        #cv2.imshow(\"Nose pig\", nose_pig)\n",
    "        #cv2.imshow(\"final nose\", final_nose)\n",
    "\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cartoon eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "from imutils.video import VideoStream\n",
    "from imutils import face_utils, translate, resize\n",
    "import time\n",
    "import dlib\n",
    "import numpy as np\n",
    "\n",
    "# Set predictor path manually instead of using argparse in Jupyter\n",
    "predictor_path = \"./shape_predictor_68_face_landmarks.dat\"  # Replace with your actual predictor path\n",
    "\n",
    "print(\"starting program.\")\n",
    "print(\"'s' starts drawing eyes.\")\n",
    "print(\"'r' to toggle recording image, and 'q' to quit\")\n",
    "\n",
    "vs = VideoStream().start()\n",
    "time.sleep(1.5)\n",
    "\n",
    "# this detects our face\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "# and this predicts our face's orientation\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "recording = False\n",
    "counter = 0\n",
    "\n",
    "class EyeList(object):\n",
    "    def __init__(self, length):\n",
    "        self.length = length\n",
    "        self.eyes = []\n",
    "\n",
    "    def push(self, newcoords):\n",
    "        if len(self.eyes) < self.length:\n",
    "            self.eyes.append(newcoords)\n",
    "        else:\n",
    "            self.eyes.pop(0)\n",
    "            self.eyes.append(newcoords)\n",
    "    \n",
    "    def clear(self):\n",
    "        self.eyes = []\n",
    "\n",
    "# start with 10 previous eye positions\n",
    "eyelist = EyeList(10)\n",
    "eyeSnake = False\n",
    "\n",
    "# get our first frame outside of loop, so we can see how our\n",
    "# webcam resized itself, and it's resolution w/ np.shape\n",
    "frame = vs.read()\n",
    "frame = resize(frame, width=800)\n",
    "\n",
    "eyelayer = np.zeros(frame.shape, dtype='uint8')\n",
    "eyemask = eyelayer.copy()\n",
    "eyemask = cv2.cvtColor(eyemask, cv2.COLOR_BGR2GRAY)\n",
    "translated = np.zeros(frame.shape, dtype='uint8')\n",
    "translated_mask = eyemask.copy()\n",
    "\n",
    "while True:\n",
    "    # read a frame from webcam, resize to be smaller\n",
    "    frame = vs.read()\n",
    "    frame = resize(frame, width=800)\n",
    "\n",
    "    # fill our masks and frames with 0 (black) on every draw loop\n",
    "    eyelayer.fill(0)\n",
    "    eyemask.fill(0)\n",
    "    translated.fill(0)\n",
    "    translated_mask.fill(0)\n",
    "\n",
    "    # the detector and predictor expect a grayscale image\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "    # if we're running the eyesnake loop (press 's' while running to enable)\n",
    "    if eyeSnake:\n",
    "        for rect in rects:\n",
    "            # the predictor is our 68-point model we loaded\n",
    "            shape = predictor(gray, rect)\n",
    "            shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "            # our dlib model returns 68 points that make up a face.\n",
    "            # the left eye is the 36th point through the 42nd. the right\n",
    "            # eye is the 42nd point through the 48th.\n",
    "            leftEye = shape[36:42]\n",
    "            rightEye = shape[42:48]\n",
    "\n",
    "            # fill our mask in the shape of our eyes\n",
    "            cv2.fillPoly(eyemask, [leftEye], 255)\n",
    "            cv2.fillPoly(eyemask, [rightEye], 255)\n",
    "\n",
    "            # copy the image from the frame onto the eyelayer using that mask\n",
    "            eyelayer = cv2.bitwise_and(frame, frame, mask=eyemask)\n",
    "\n",
    "            # we use this to get an x and y coordinate for the pasting of eyes\n",
    "            x, y, w, h = cv2.boundingRect(eyemask)\n",
    "\n",
    "            # push this onto our list\n",
    "            eyelist.push([x, y])\n",
    "\n",
    "            # finally, draw our eyes, in reverse order\n",
    "            for i in reversed(eyelist.eyes):\n",
    "                # first, translate the eyelayer with just the eyes\n",
    "                translated1 = translate(eyelayer, i[0] - x, i[1] - y)\n",
    "                # next, translate its mask\n",
    "                translated1_mask = translate(eyemask, i[0] - x, i[1] - y)\n",
    "                # add it to the existing translated eyes mask (not actual add because of\n",
    "                # risk of overflow)\n",
    "                translated_mask = np.maximum(translated_mask, translated1_mask)\n",
    "                # cut out the new translated mask\n",
    "                translated = cv2.bitwise_and(translated, translated, mask=255 - translated1_mask)\n",
    "                # paste in the newly translated eye position\n",
    "                translated += translated1\n",
    "        # again, cut out the translated mask\n",
    "        frame = cv2.bitwise_and(frame, frame, mask=255 - translated_mask)\n",
    "        # and paste in the translated eye image\n",
    "        frame += translated\n",
    "\n",
    "    # display the current frame, and check to see if user pressed a key\n",
    "    cv2.imshow(\"eye glitch\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if recording:\n",
    "        # create a directory called \"image_seq\", and we'll be able to create gifs in ffmpeg\n",
    "        # from image sequences\n",
    "        cv2.imwrite(\"image_seq/%05d.png\" % counter, frame)\n",
    "        counter += 1\n",
    "\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "    if key == ord(\"s\"):\n",
    "        eyeSnake = not eyeSnake\n",
    "        eyelist.clear()\n",
    "\n",
    "    if key == ord(\"r\"):\n",
    "        recording = not recording\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mi_entorno",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
